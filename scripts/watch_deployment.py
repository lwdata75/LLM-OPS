"""
Surveiller le d√©ploiement en temps r√©el.
"""
import os
import time
from google.cloud import aiplatform
from dotenv import load_dotenv

load_dotenv()

PROJECT_ID = os.getenv("GCP_PROJECT_ID", "aerobic-polygon-460910-v9")
REGION = os.getenv("GCP_REGION", "europe-west2")
ENDPOINT_ID = "5724492940806455296"

aiplatform.init(project=PROJECT_ID, location=REGION)

print(f"\n{'='*80}")
print(f"‚è≥ SURVEILLANCE DU D√âPLOIEMENT")
print(f"{'='*80}\n")
print(f"Endpoint: nutrition-assistant-endpoint")
print(f"ID: {ENDPOINT_ID}")
print(f"R√©gion: {REGION}\n")
print(f"üîó Console: https://console.cloud.google.com/vertex-ai/online-prediction/endpoints/{ENDPOINT_ID}?project={PROJECT_ID}\n")
print(f"{'='*80}\n")

print("üîÑ V√©rification toutes les 30 secondes...")
print("   Appuyez sur Ctrl+C pour arr√™ter\n")

check_count = 0
start_time = time.time()

try:
    while True:
        check_count += 1
        elapsed = time.time() - start_time
        
        print(f"[{time.strftime('%H:%M:%S')}] Check #{check_count} (apr√®s {int(elapsed/60)} min {int(elapsed%60)} sec)")
        
        try:
            endpoint = aiplatform.Endpoint(f"projects/432566588992/locations/{REGION}/endpoints/{ENDPOINT_ID}")
            
            if endpoint.gca_resource.deployed_models:
                print(f"\n{'='*80}")
                print("‚úÖ D√âPLOIEMENT TERMIN√â!")
                print(f"{'='*80}\n")
                
                for deployed_model in endpoint.gca_resource.deployed_models:
                    print(f"üì¶ Mod√®le d√©ploy√©:")
                    print(f"   Nom: {deployed_model.display_name}")
                    print(f"   ID: {deployed_model.id}")
                    
                    if hasattr(deployed_model, 'dedicated_resources'):
                        if deployed_model.dedicated_resources.machine_spec:
                            print(f"   Machine: {deployed_model.dedicated_resources.machine_spec.machine_type}")
                            if deployed_model.dedicated_resources.machine_spec.accelerator_type:
                                accel = deployed_model.dedicated_resources.machine_spec.accelerator_type
                                count = deployed_model.dedicated_resources.machine_spec.accelerator_count
                                print(f"   GPU: {accel} x {count}")
                    print()
                
                print(f"‚è±Ô∏è  Temps total: {int(elapsed/60)} minutes {int(elapsed%60)} secondes\n")
                print(f"{'='*80}")
                print("üß™ TESTEZ MAINTENANT!")
                print(f"{'='*80}\n")
                print("Option 1 - Test rapide:")
                print('  python scripts/test_endpoint.py --prompt "What are the benefits of spinach?"\n')
                print("Option 2 - Interface web:")
                print("  chainlit run src/app/main.py -w")
                print("  Puis allez sur: http://localhost:8000\n")
                print(f"{'='*80}\n")
                break
            else:
                print(f"   ‚è≥ Toujours en cours de d√©ploiement...")
                print(f"   Prochaine v√©rification dans 30 secondes...\n")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur lors de la v√©rification: {e}")
            print(f"   Nouvelle tentative dans 30 secondes...\n")
        
        time.sleep(30)
        
except KeyboardInterrupt:
    print(f"\n\n{'='*80}")
    print("‚è∏Ô∏è  Surveillance arr√™t√©e par l'utilisateur")
    print(f"{'='*80}\n")
    print(f"Temps √©coul√©: {int(elapsed/60)} minutes {int(elapsed%60)} secondes")
    print(f"\nVous pouvez relancer ce script √† tout moment:")
    print(f"  python scripts/check_endpoint_status.py\n")
    print(f"Ou v√©rifier dans la console:")
    print(f"  https://console.cloud.google.com/vertex-ai/online-prediction/endpoints/{ENDPOINT_ID}?project={PROJECT_ID}\n")
    print(f"{'='*80}\n")
